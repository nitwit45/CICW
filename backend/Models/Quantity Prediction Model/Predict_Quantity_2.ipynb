{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Quantity with 0.3 Test Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Final Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer Id  Order Customer Id  Order Id  Order Item Cardprod Id  \\\n",
      "0        20755              20755     77202                    1360   \n",
      "1        19492              19492     75939                    1360   \n",
      "2        19491              19491     75938                    1360   \n",
      "3        19490              19490     75937                    1360   \n",
      "4        19489              19489     75936                    1360   \n",
      "\n",
      "   Product Card Id  Product Price   Category Name Department city  \\\n",
      "0             1360         327.75  Sporting Goods          Caguas   \n",
      "1             1360         327.75  Sporting Goods          Caguas   \n",
      "2             1360         327.75  Sporting Goods        San Jose   \n",
      "3             1360         327.75  Sporting Goods     Los Angeles   \n",
      "4             1360         327.75  Sporting Goods          Caguas   \n",
      "\n",
      "  Department country Customer Segment Department state  \\\n",
      "0        Puerto Rico         Consumer               PR   \n",
      "1        Puerto Rico         Consumer               PR   \n",
      "2            EE. UU.         Consumer               CA   \n",
      "3            EE. UU.      Home Office               CA   \n",
      "4        Puerto Rico        Corporate               PR   \n",
      "\n",
      "            Customer Street  Order City Order Country    Order Region  \\\n",
      "0  5365 Noble Nectar Island      Bekasi     Indonesia  Southeast Asia   \n",
      "1          2679 Rustic Loop     Bikaner         India      South Asia   \n",
      "2      8510 Round Bear Gate     Bikaner         India      South Asia   \n",
      "3           3200 Amber Bend  Townsville     Australia         Oceania   \n",
      "4  8671 Iron Anchor Corners  Townsville     Australia         Oceania   \n",
      "\n",
      "       Order State order date (DateOrders)  Product Name  Order Item Quantity  \\\n",
      "0  Java Occidental         1/31/2018 22:56  Smart watch                   100   \n",
      "1         Rajastán         1/13/2018 12:27  Smart watch                   100   \n",
      "2         Rajastán         1/13/2018 12:06  Smart watch                   100   \n",
      "3       Queensland         1/13/2018 11:45  Smart watch                   100   \n",
      "4       Queensland         1/13/2018 11:24  Smart watch                   100   \n",
      "\n",
      "   Customer Zipcode  \n",
      "0             725.0  \n",
      "1             725.0  \n",
      "2           95125.0  \n",
      "3           90027.0  \n",
      "4             725.0  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from a CSV file\n",
    "df = pd.read_csv('cleaned_data_final.csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Id                  int64\n",
      "Order Customer Id            int64\n",
      "Order Id                     int64\n",
      "Order Item Cardprod Id       int64\n",
      "Product Card Id              int64\n",
      "Product Price              float64\n",
      "Category Name               object\n",
      "Department city             object\n",
      "Department country          object\n",
      "Customer Segment            object\n",
      "Department state            object\n",
      "Customer Street             object\n",
      "Order City                  object\n",
      "Order Country               object\n",
      "Order Region                object\n",
      "Order State                 object\n",
      "order date (DateOrders)     object\n",
      "Product Name                object\n",
      "Order Item Quantity          int64\n",
      "Customer Zipcode           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Select relevant features and target variable\n",
    "features = ['Category Name','Department city','Department country', 'Customer Id','Customer Segment',\n",
    "            'Department state','Customer Street','Order City','Order Country','Order Customer Id','order date (DateOrders)','Order Id','Order Item Cardprod Id',\n",
    "            'Order Region','Order State','Product Card Id','Product Name','Product Price','Customer Zipcode']\n",
    "target = 'Order Item Quantity'\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define preprocessing steps (one-hot encoding for categorical variables)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', ['Customer Id','Order Customer Id','Order Id','Order Item Cardprod Id','Product Card Id','Product Price','Customer Zipcode']),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['Category Name', 'Department city', 'Department country','Customer Segment','Department state','Customer Street','Order City','Order Country','order date (DateOrders)','Order Region','Order State','Product Name'])\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 67.04523508925801\n",
      "Mean Squared Error: 10292.36922110403\n",
      "R-squared: 0.39309844649869563\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a pipeline with preprocessing and the linear regression model\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('regressor', LinearRegression())])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 57.90017743979721\n",
      "Mean Squared Error: 10492.20040557668\n",
      "R-squared: 0.38131516767443996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create a pipeline with preprocessing and the linear regression model\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('regressor', RandomForestRegressor(random_state=42))])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rn = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred_rn)\n",
    "mse = mean_squared_error(y_test, y_pred_rn)\n",
    "r2_rn = r2_score(y_test, y_pred_rn)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2_rn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to randomforest_model_final.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model to a file using pickle\n",
    "model_filename_pickle = 'randomforest_model_final.pkl'\n",
    "with open(model_filename_pickle, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "print(f'Model saved to {model_filename_pickle}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 71.60456273764258\n",
      "Mean Squared Error: 18893.78960709759\n",
      "R-squared: -0.11409433705141914\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# Create a pipeline with preprocessing and the linear regression model\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('regressor', DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "mse = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2_rf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 58.19190518049233\n",
      "Mean Squared Error: 9553.513766383256\n",
      "R-squared: 0.43666591999775184\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# Create a pipeline with preprocessing and the linear regression model\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('regressor', xgb.XGBRegressor(random_state=42))])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_n = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred_n)\n",
    "mse = mean_squared_error(y_test, y_pred_n)\n",
    "r2_n = r2_score(y_test, y_pred_n)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2_n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to xgbooost_model_final.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model to a file using pickle\n",
    "model_filename_pickle = 'xgbooost_model_final.pkl'\n",
    "with open(model_filename_pickle, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "print(f'Model saved to {model_filename_pickle}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 58.19190518049233\n",
      "Mean Squared Error: 9553.513766383256\n",
      "R-squared: 0.43666591999775184\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# Create a pipeline with preprocessing and the linear regression model\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('regressor', xgb.XGBRegressor(random_state=42))])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_n = model.predict(X_test)\n",
    "\n",
    "# Round the predictions to the nearest integer\n",
    "rounded_predictions = [round(pred) for pred in y_pred_n]\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred_n)\n",
    "mse = mean_squared_error(y_test, y_pred_n)\n",
    "r2_n = r2_score(y_test, y_pred_n)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2_n}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to xgboost_model_final.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model to a file using pickle\n",
    "model_filename_pickle = 'xgboost_model_final.pkl'\n",
    "with open(model_filename_pickle, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "print(f'Model saved to {model_filename_pickle}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 76.26869455006337\n",
      "Mean Squared Error: 22787.325728770596\n",
      "R-squared: -0.3436812348874956\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Create a pipeline with preprocessing and the linear regression model\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('regressor', LogisticRegression(max_iter=5000))])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_n = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred_n)\n",
    "mse = mean_squared_error(y_test, y_pred_n)\n",
    "r2_n = r2_score(y_test, y_pred_n)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2_n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a Ridge Regression model\n",
    "alpha = 1.0  # Regularization strength, adjust as needed\n",
    "ridge_model = Ridge(alpha=alpha)\n",
    "\n",
    "# Create a pipeline with preprocessing and the Ridge Regression model\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('regressor', ridge_model)])\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'R-squared: {r2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for row 0: 136.0\n",
      "Prediction for row 1: 100.0\n",
      "Prediction for row 2: 100.0\n",
      "Prediction for row 3: 251.0\n",
      "Prediction for row 4: 100.0\n",
      "Prediction for row 5: 171.0\n",
      "Prediction for row 6: 304.0\n",
      "Prediction for row 7: 237.0\n",
      "Prediction for row 8: 100.0\n",
      "Prediction for row 9: 140.0\n",
      "Prediction for row 10: 234.0\n",
      "Prediction for row 11: 380.0\n",
      "Prediction for row 12: 225.0\n",
      "Prediction for row 13: 322.0\n",
      "Prediction for row 14: 295.0\n",
      "Prediction for row 15: 100.0\n",
      "Prediction for row 16: 204.0\n",
      "Prediction for row 17: 100.0\n",
      "Prediction for row 18: 313.0\n",
      "Prediction for row 19: 190.0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load the model\n",
    "with open('randomforest_model_final.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "df_test = pd.read_csv('test_dataset_final.csv')\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "new_predictions = loaded_model.predict(df_test)\n",
    "\n",
    "# Make predictions and print each prediction on a new line\n",
    "for index, row in df_test.iterrows():\n",
    "    # Assuming your model expects a 2D array, reshape the row\n",
    "    # prediction = loaded_model.predict(row.values.reshape(1, -1))\n",
    "    print(f'Prediction for row {index}: {new_predictions[index]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for row 0: 255.23097229003906\n",
      "Prediction for row 1: 100.27078247070312\n",
      "Prediction for row 2: 100.27078247070312\n",
      "Prediction for row 3: 274.0972595214844\n",
      "Prediction for row 4: 101.22743225097656\n",
      "Prediction for row 5: 236.32937622070312\n",
      "Prediction for row 6: 286.96917724609375\n",
      "Prediction for row 7: 302.649658203125\n",
      "Prediction for row 8: 100.27078247070312\n",
      "Prediction for row 9: 223.7647247314453\n",
      "Prediction for row 10: 281.6730651855469\n",
      "Prediction for row 11: 300.88470458984375\n",
      "Prediction for row 12: 252.06251525878906\n",
      "Prediction for row 13: 293.0944519042969\n",
      "Prediction for row 14: 270.6311340332031\n",
      "Prediction for row 15: 100.27078247070312\n",
      "Prediction for row 16: 262.7432861328125\n",
      "Prediction for row 17: 99.94042205810547\n",
      "Prediction for row 18: 275.80047607421875\n",
      "Prediction for row 19: 249.7384796142578\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load the model\n",
    "with open('xgbooost_model_final.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "df_test = pd.read_csv('test_dataset_final.csv')\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "new_predictions = loaded_model.predict(df_test)\n",
    "\n",
    "# Make predictions and print each prediction on a new line\n",
    "for index, row in df_test.iterrows():\n",
    "    # Assuming your model expects a 2D array, reshape the row\n",
    "    # prediction = loaded_model.predict(row.values.reshape(1, -1))\n",
    "    print(f'Prediction for row {index}: {new_predictions[index]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for row 0: 255\n",
      "Prediction for row 1: 100\n",
      "Prediction for row 2: 100\n",
      "Prediction for row 3: 274\n",
      "Prediction for row 4: 101\n",
      "Prediction for row 5: 236\n",
      "Prediction for row 6: 287\n",
      "Prediction for row 7: 303\n",
      "Prediction for row 8: 100\n",
      "Prediction for row 9: 224\n",
      "Prediction for row 10: 282\n",
      "Prediction for row 11: 301\n",
      "Prediction for row 12: 252\n",
      "Prediction for row 13: 293\n",
      "Prediction for row 14: 271\n",
      "Prediction for row 15: 100\n",
      "Prediction for row 16: 263\n",
      "Prediction for row 17: 100\n",
      "Prediction for row 18: 276\n",
      "Prediction for row 19: 250\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load the model\n",
    "with open('xgboost_model_final.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "df_test = pd.read_csv('test_dataset_final.csv')\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "new_predictions = loaded_model.predict(df_test)\n",
    "\n",
    "# Round the predictions to the nearest integer\n",
    "rounded_predictions = [round(pred) for pred in new_predictions]\n",
    "\n",
    "# Make predictions and print each prediction on a new line\n",
    "for index, row in df_test.iterrows():\n",
    "    # Assuming your model expects a 2D array, reshape the row\n",
    "    # prediction = loaded_model.predict(row.values.reshape(1, -1))\n",
    "    print(f'Prediction for row {index}: {rounded_predictions[index]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
